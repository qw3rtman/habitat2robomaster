{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for Network:\n\tMissing key(s) in state_dict: \"fc3.weight\", \"fc3.bias\". \n\tsize mismatch for fc2.weight: copying a param with shape torch.Size([1, 64]) from checkpoint, the shape in current model is torch.Size([2, 64]).\n\tsize mismatch for fc2.bias: copying a param with shape torch.Size([1]) from checkpoint, the shape in current model is torch.Size([2]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-ff7de9f6c0bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'models/habitat-ppo-depth/001/model_010.t7'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/robot/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m    828\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m--> 830\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m    831\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Network:\n\tMissing key(s) in state_dict: \"fc3.weight\", \"fc3.bias\". \n\tsize mismatch for fc2.weight: copying a param with shape torch.Size([1, 64]) from checkpoint, the shape in current model is torch.Size([2, 64]).\n\tsize mismatch for fc2.bias: copying a param with shape torch.Size([1]) from checkpoint, the shape in current model is torch.Size([2])."
     ]
    }
   ],
   "source": [
    "from habitat.sims.habitat_simulator.actions import HabitatSimActions\n",
    "\n",
    "from habitat_dataset import get_dataset, HabitatDataset\n",
    "# from model import Network\n",
    "\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "ACTIONS = {v: k for k, v in HabitatSimActions._known_actions.items()}\n",
    "\n",
    "transform_ = transforms.ToPILImage()\n",
    "dataset = HabitatDataset('data/depth/train/0002')#get_dataset('test_ppo_data')\n",
    "\n",
    "net = Network()\n",
    "net.load_state_dict(torch.load('models/habitat-ppo-depth/001/model_010.t7', map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from resnet import ResnetBase\n",
    "\n",
    "def spatial_softmax_base():\n",
    "    return nn.Sequential(\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ConvTranspose2d(512, 256, 3, 2, 1, 1),\n",
    "            nn.ReLU(True),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ConvTranspose2d(256, 128, 3, 2, 1, 1),\n",
    "            nn.ReLU(True),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ConvTranspose2d(128, 64, 3, 2, 1, 1),\n",
    "            nn.ReLU(True)\n",
    "    )\n",
    "\n",
    "\n",
    "class Network(ResnetBase):\n",
    "    def __init__(self, resnet_model='resnet34', **resnet_kwargs):\n",
    "        resnet_kwargs['input_channel'] = resnet_kwargs.get('input_channel', 3)\n",
    "\n",
    "        super().__init__(resnet_model, **resnet_kwargs)\n",
    "\n",
    "        self.normalize = nn.BatchNorm2d(resnet_kwargs['input_channel'])\n",
    "        self.deconv = spatial_softmax_base()\n",
    "        self.extract = nn.Sequential(\n",
    "                nn.BatchNorm2d(64),\n",
    "                nn.Conv2d(64, 5, 1, 1, 0))#,\n",
    "                #common.SpatialSoftmax(temperature))\n",
    "        \n",
    "        self.fc1 = nn.Linear(64, 1)\n",
    "        self.fc2 = nn.Linear(64, 2)\n",
    "        self.fc3 = nn.Linear(10, 5)\n",
    "\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    # TODO: take start_pos, start_rot, end_pos\n",
    "    def forward(self, rgb, meta):\n",
    "        rgb = self.normalize(rgb)\n",
    "        rgb = self.conv(rgb)\n",
    "        rgb = self.deconv(rgb)\n",
    "        rgb = self.extract(rgb)\n",
    "        rgb = self.fc1(rgb).squeeze()\n",
    "        rgb = self.fc2(rgb)\n",
    "        x = self.fc3(rgb.view((-1, 10)) + meta)\n",
    "\n",
    "        return self.softmax(x)\n",
    "\n",
    "net = Network()\n",
    "# net.load_state_dict(torch.load('models/habitat-ppo-depth/001/model_010.t7', map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7.0419e-02, 5.4644e-04, 2.0197e-02, 2.8781e-02, 8.8006e-01]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 20\n",
    "rgb, _, _, action, meta = dataset[i]\n",
    "\n",
    "net(rgb.unsqueeze(dim=0), meta).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 2])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta.reshape(5, -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for rgb, _, _, action, _ in dataset:\n",
    "    img = np.array(transform_(rgb))\n",
    "\n",
    "    cv2.putText(img, 'Predicted: {}'.format(ACTIONS[(net(rgb.unsqueeze(dim=0)).detach()).argmax().item()]),\n",
    "        (10, 20),\n",
    "        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "        0.5,\n",
    "        (255,255,255),\n",
    "        2)\n",
    "\n",
    "    cv2.putText(img, 'Actual:    {}'.format(ACTIONS[action.argmax().item()]),\n",
    "        (10, 40),\n",
    "        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "        0.5,\n",
    "        (255,255,255),\n",
    "        2)\n",
    "\n",
    "    cv2.imshow('rgb', img)\n",
    "    cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
